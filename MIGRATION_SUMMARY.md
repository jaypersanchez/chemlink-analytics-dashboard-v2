# ChemLink Analytics V2 - Kubernetes Migration Summary

## âœ… Migration Complete!

Your ChemLink Analytics V2 platform is now ready to run on both **localhost** and **Kubernetes**! 

## What Was Done

### 1. Dashboard Code Updates âœ“
- **Updated `app.py`** to support configurable database connection:
  - Added `ANALYTICS_DB_PORT` environment variable support
  - Added `ANALYTICS_DB_NAME` environment variable support
  - Now works with both localhost:5432 and Kubernetes (via port-forward to localhost:5433)

### 2. Configuration Files âœ“
- **Updated `.env.example`** with both localhost and Kubernetes configurations
- Added clear documentation for each configuration mode
- Maintained backward compatibility with existing setups

### 3. Migration Scripts âœ“
Created two executable scripts for easy switching:

**`switch-to-kube.sh`**
- Sets `DATA_ENV=kube` in ETL project
- Updates dashboard to connect to `localhost:5433/chemlink_analytics_dev`
- Validates port forwarding is active

**`switch-to-localhost.sh`**
- Sets `DATA_ENV=local` in ETL project  
- Updates dashboard to connect to `localhost:5432/chemlink_analytics`
- Restores default localhost configuration

### 4. Documentation âœ“
Created comprehensive guides:

- **KUBERNETES_MIGRATION_GUIDE.md** - Complete step-by-step migration instructions
- **QUICK_REFERENCE.md** - Quick command reference for daily use
- **Updated README.md** - Added Kubernetes deployment section
- **This file (MIGRATION_SUMMARY.md)** - Summary of what was implemented

## Important: What Stayed the Same

### ETL Scripts - NO CHANGES REQUIRED! ðŸŽ‰

The ETL scripts in `~/projects/chemlink-analytics-db/` **already had Kubernetes support** built in:

- `extract.py` - Already respects `DATA_ENV` variable
- `transform.py` - Already respects `DATA_ENV` variable
- `aggregate.py` - Already respects `DATA_ENV` variable
- `db_config.py` - Already has logic to route to Kubernetes when `DATA_ENV=kube`

This means **zero code changes** were needed in the ETL pipeline - it was already Kubernetes-ready!

## Architecture Overview

### Data Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PRODUCTION DATABASES      â”‚
â”‚   - ChemLink Service        â”‚
â”‚   - Engagement Platform     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ (Read-Only Extract)
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETL PIPELINE              â”‚
â”‚   - extract.py              â”‚
â”‚   - transform.py            â”‚
â”‚   - aggregate.py            â”‚
â”‚   (DATA_ENV determines      â”‚
â”‚    target database)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   TARGET DATABASE             â”‚
   â”‚                               â”‚
   â”‚  Localhost:                   â”‚
   â”‚  :5432/chemlink_analytics     â”‚
   â”‚                               â”‚
   â”‚         OR                    â”‚
   â”‚                               â”‚
   â”‚  Kubernetes:                  â”‚
   â”‚  :5433/chemlink_analytics_dev â”‚
   â”‚  (via kubectl port-forward)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   DASHBOARD V2                â”‚
   â”‚   - Flask app (app.py)        â”‚
   â”‚   - Charts & Analytics        â”‚
   â”‚   - Port 5001                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## How To Use

### First Time Setup on Kubernetes

1. **Set up port forwarding** to Kubernetes PostgreSQL:
   ```bash
   kubectl port-forward -n your-namespace pod/postgres-pod 5433:5432
   ```

2. **Create the database** on Kubernetes:
   ```bash
   # Option A: Copy schema from localhost
   pg_dump -h localhost -p 5432 -U postgres -d chemlink_analytics --schema-only > /tmp/schema.sql
   psql -h localhost -p 5433 -U dev -c "CREATE DATABASE chemlink_analytics_dev;"
   psql -h localhost -p 5433 -U dev -d chemlink_analytics_dev < /tmp/schema.sql
   
   # Option B: Run schema creation scripts
   cd ~/projects/chemlink-analytics-db
   psql -h localhost -p 5433 -U dev -d chemlink_analytics_dev < schema/01_staging_schema.sql
   psql -h localhost -p 5433 -U dev -d chemlink_analytics_dev < schema/02_core_schema.sql
   psql -h localhost -p 5433 -U dev -d chemlink_analytics_dev < schema/03_aggregates_schema.sql
   ```

3. **Switch to Kubernetes mode**:
   ```bash
   cd ~/projects/chemlink-analytics-dashboard-V2
   ./switch-to-kube.sh
   ```

4. **Run the ETL pipeline**:
   ```bash
   cd ~/projects/chemlink-analytics-db
   source venv/bin/activate
   python scripts/extract.py
   python scripts/transform.py
   python scripts/aggregate.py
   ```

5. **Start the dashboard**:
   ```bash
   cd ~/projects/chemlink-analytics-dashboard-V2
   source venv/bin/activate
   python app.py
   ```

6. **Open browser** to http://localhost:5001

### Daily Use

**Switch to Kubernetes:**
```bash
./switch-to-kube.sh
# Ensure port forwarding is active
python app.py
```

**Switch back to Localhost:**
```bash
./switch-to-localhost.sh
python app.py
```

## Environment Variables Reference

### ETL Project (`~/projects/chemlink-analytics-db/.env`)

```bash
# Switch between modes
DATA_ENV=local   # or DATA_ENV=kube

# Production source databases (unchanged)
CHEMLINK_PRD_DB_HOST=...
ENGAGEMENT_PRD_DB_HOST=...

# Localhost analytics database
ANALYTICS_DB_HOST=localhost
ANALYTICS_DB_PORT=5432
ANALYTICS_DB_NAME=chemlink_analytics
ANALYTICS_DB_USER=postgres
ANALYTICS_DB_PASSWORD=postgres

# Kubernetes analytics database (via port-forward)
ANALYTICS_DEV_DB_HOST=localhost
ANALYTICS_DEV_DB_PORT=5433
ANALYTICS_DEV_DB_NAME=chemlink_analytics_dev
ANALYTICS_DEV_DB_USER=dev
ANALYTICS_DEV_DB_PASSWORD=dev
```

### Dashboard Project (`~/projects/chemlink-analytics-dashboard-V2/.env`)

**For Localhost:**
```bash
ANALYTICS_DB_HOST=localhost
ANALYTICS_DB_PORT=5432
ANALYTICS_DB_NAME=chemlink_analytics
ANALYTICS_DB_USER=postgres
ANALYTICS_DB_PASSWORD=postgres
```

**For Kubernetes:**
```bash
ANALYTICS_DB_HOST=localhost
ANALYTICS_DB_PORT=5433
ANALYTICS_DB_NAME=chemlink_analytics_dev
ANALYTICS_DB_USER=dev
ANALYTICS_DB_PASSWORD=dev
```

## Key Benefits

âœ… **Zero Code Changes to ETL** - Existing infrastructure already supported Kubernetes  
âœ… **Simple Switching** - One script to switch between localhost and Kubernetes  
âœ… **Port Forwarding** - No direct Kubernetes networking needed, works via localhost  
âœ… **Backward Compatible** - Localhost mode still works exactly as before  
âœ… **Production Safe** - Still extracts from PROD (read-only), writes to separate analytics DB  
âœ… **Easy Testing** - Switch modes instantly for testing and development  

## Testing Checklist

Before considering the migration complete, verify:

- [ ] Port forwarding works: `lsof -i :5433`
- [ ] Database exists on Kubernetes: `psql -h localhost -p 5433 -U dev -l | grep chemlink_analytics_dev`
- [ ] ETL extract succeeds with `DATA_ENV=kube`
- [ ] ETL transform succeeds 
- [ ] ETL aggregate succeeds
- [ ] Dashboard connects to Kubernetes database
- [ ] All dashboard charts load with data
- [ ] Can switch back to localhost mode successfully
- [ ] Localhost mode still works after switching

## Support & Troubleshooting

See the following files for help:

- **KUBERNETES_MIGRATION_GUIDE.md** - Detailed migration steps and troubleshooting
- **QUICK_REFERENCE.md** - Quick command reference
- **README.md** - General project documentation

## Next Steps

Once Kubernetes migration is verified:

1. **Schedule ETL on Kubernetes** - Set up CronJob to run nightly ETL
2. **Deploy Dashboard to Kubernetes** - Containerize and deploy as K8s service
3. **Remove Port Forwarding** - Connect directly to Kubernetes PostgreSQL service
4. **Set Up Monitoring** - Add Prometheus/Grafana for observability
5. **Implement Backups** - Automated backup strategy for Kubernetes PostgreSQL

## Credits

Migration implemented: 2025-01-13  
Architecture: Dual-mode (localhost/Kubernetes) with environment-based switching  
Compatibility: Backward compatible with existing localhost setup
